<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Swift">
    
    <title>
        
            自定义CUDA算子融合实现模型推理加速 |
        
        Swift&#39;s Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    
        <link rel="shortcut icon" href="/images/huoyin.png">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.0.7/font/css/fontawesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.0.7/font/css/regular.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.0.7/font/css/solid.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.0.7/font/css/brands.min.css">
    
        
            
                
<link rel="stylesheet" href="/css/custom.css">

            
        
    
    <script class="keep-theme-configurations">
    const KEEP = window.KEEP || {}
    KEEP.hexo_config = {"hostname":"example.com","root":"/","language":"en","path":"search.xml"}
    KEEP.theme_config = {"base_info":{"primary_color":"#0066cc","title":"Swift's Blog","author":"Swift","avatar":"/images/atom.svg","logo":"/images/atom.svg","favicon":"/images/huoyin.png"},"menu":{"Archives":"/archives","Tags":"/tags","Categories":"/categories","Links":"/links","About":"/about"},"first_screen":{"enable":true,"background_img":"/images/bg2.svg","background_img_dark":"/images/bg2.svg","description":"Keep writing and Keep loving!","hitokoto":false},"social_contact":{"enable":true,"links":{"github":"https://github.com/TransformersWsz","weixin":null,"qq":null,"weibo":null,"zhihu":null,"twitter":null,"facebook":null,"email":"antcoder@outlook.com"}},"scroll":{"progress_bar":true,"percent":false,"hide_header":true},"home":{"category":true,"tag":true,"announcement":null},"post":{"author_badge":{"enable":true,"level_badge":true,"custom_badge":["One","Two","Three"]},"word_count":{"wordcount":false,"min2read":false},"datetime_format":"YYYY-MM-DD HH:mm:ss","copyright_info":false,"share":true,"reward":{"enable":true,"img_link":"https://github.com/TransformersWsz/picx-images-hosting/raw/master/code6.8s3kp5tiv9.webp","text":"请作者喝杯奶茶🧋"}},"code_block":{"tools":{"enable":true,"style":"mac"},"highlight_theme":"obsidian"},"toc":{"enable":true,"number":true,"expand_all":true,"init_open":false,"layout":"left"},"website_count":{"busuanzi_count":{"enable":true,"site_uv":true,"site_pv":true,"page_pv":true}},"local_search":{"enable":true,"preload":true},"comment":{"enable":false,"use":"valine","valine":{"appid":null,"appkey":null,"server_urls":null,"placeholder":null},"gitalk":{"github_id":null,"github_admins":null,"repository":null,"client_id":null,"client_secret":null,"proxy":null},"twikoo":{"env_id":null,"region":null,"version":"1.6.21"},"waline":{"server_url":null,"reaction":false,"version":2},"giscus":{"repo":null,"repo_id":null,"category":"Announcements","category_id":null,"reactions_enabled":false},"artalk":{"server":null},"disqus":{"shortname":null}},"rss":{"enable":false},"lazyload":{"enable":false},"cdn":{"enable":true,"provider":"cdnjs"},"pjax":{"enable":true},"footer":{"since":2017,"word_count":false,"icp":{"enable":false,"record_code":null,"url":"https://beian.miit.gov.cn"},"site_deploy":{"enable":true,"provider":"github","url":null},"shields_style":{"enable":false,"custom":[{"link_url":null,"img_url":null}]}},"inject":{"enable":true,"css":["/css/custom.css"],"js":[null]},"root":"","links":[{"name":"heary","link":"https://heary.cn/","avatar":"https://raw.githubusercontent.com/TransformersWsz/picx-images-hosting/master/image.5c0vutsght.webp","description":"本科及研究生学长"},{"name":"知识就是力量","link":"https://tricktreat.github.io/","avatar":"https://avatars.githubusercontent.com/u/25740077?v=4","description":"学长"},{"name":"myths","link":"https://blog.mythsman.com/","avatar":"https://blog.mythsman.com/content/images/2019/07/----_20190713220203.jpg","description":"丁神"},{"name":"mikito","link":"https://mikito.mythsman.com/","avatar":"https://mikito.mythsman.com/content/images/2019/07/2-1.jpg","description":"丁神女友"},{"name":"老猫轩仔","link":"https://www.agedcat.com/","avatar":"https://raw.githubusercontent.com/TransformersWsz/picx-images-hosting/master/image.1lbq9l6ju9.webp","description":"郭尔轩"},{"name":"韦阳","link":"https://godweiyang.com/","avatar":"https://raw.githubusercontent.com/TransformersWsz/picx-images-hosting/master/image.1e8ie5lpze.webp","description":"华师大本硕第一、LightSeq作者"},{"name":"x-hansong","link":"https://www.zhihu.com/people/xiao-han-song","avatar":"https://avatars.githubusercontent.com/u/5747697?v=4","description":"华南理工本科、支付宝工程师"},{"name":"指间的诗意","link":"https://xpoet.cn/","avatar":"https://xpoet.cn/images/avatar.png","description":"hexo-theme-keep & PicX的开发者"},{"name":"Molunerfinn","link":"https://molunerfinn.com/","avatar":"https://avatars.githubusercontent.com/u/12621342?v=4","description":"PicGo的开发者、WXG员工"},{"name":"Jerry Qu","link":"https://imququ.com/","avatar":"https://cdn.jsdelivr.net/gh/TransformersWsz/image_hosting@master/jerryqu.3yhp1au3nii0.webp","description":"前端开发大佬、现在转向偏管理"},{"name":"Qian Liu","link":"https://siviltaram.github.io/","avatar":"https://siviltaram.github.io/images/profile.png","description":"北航博士、NLP论文高产、热衷知识分享"},{"name":"浩然","link":"https://ayanamirei1997.github.io/","avatar":"https://avatars.githubusercontent.com/u/31766871?v=4","description":"本科舍友及同学"},{"name":"海鸥","link":"https://hyrious.me/","avatar":"https://avatars.githubusercontent.com/u/8097890?v=4","description":"本科舍友及同学"},{"name":"李长顺","link":"https://zangailcs.github.io/","avatar":"https://transformerswsz.github.io/2019/09/19/picture%20bed/lcs.jpeg","description":"东南大学研究生同学"},{"name":"老石谈芯","link":"https://shilicon.com/","avatar":"https://raw.githubusercontent.com/TransformersWsz/picx-images-hosting/master/image.1e8ie5iwsh.webp","description":"帝国理工博士、芯片工程师"},{"name":"LZY","link":"https://blog.luzy.top/","avatar":"https://avatars.githubusercontent.com/u/43703357?v=4","description":"东南大学本科生"},{"name":"wulc","link":"https://wulc.me/","avatar":"https://wulc.me/files/profile.jpg","description":"字节广告算法工程师"},{"name":"Lilian Weng","link":"https://lilianweng.github.io/","avatar":"https://avatars.githubusercontent.com/u/901179?v=4","description":"OpenAI工程师"},{"name":"Hugging Face","link":"https://huggingface.co/blog","avatar":"https://huggingface.co/front/assets/huggingface_logo-noborder.svg","description":"Hugging Face官方博客"},{"name":"小小将","link":"https://www.zhihu.com/people/xiaohuzc/posts","avatar":"https://pica.zhimg.com/v2-4c580ad38bc656abf65b1a7fb14d4573_xl.jpg?source=32738c0c","description":"知乎上的某位大佬"},{"name":"BlueFishManCN","link":"https://bluefishmancn.github.io/home/","avatar":"https://avatars.githubusercontent.com/u/13911814?v=4","description":"百度广告算法专家"},{"name":"苏剑林","link":"https://spaces.ac.cn/","avatar":"https://spaces.ac.cn/usr/themes/geekg/images/avatar.png","description":"苏神"},{"name":"梦里风林","link":"https://blog.cweihang.io/","avatar":"https://raw.githubusercontent.com/TransformersWsz/picx-images-hosting/master/d479d2df7bcf6c7933b481bd83e4ce8a_xl.5mny5pw0es.webp","description":"华南理工本硕、大疆CV算法工程师"},{"name":"Lianmin Zheng","link":"https://lmzheng.net/","avatar":"https://raw.githubusercontent.com/TransformersWsz/picx-images-hosting/master/15100009.5fkqaac93c.webp","description":"xAI工程师、SGLang核心开发者"}],"version":"4.0.7"}
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"}
    KEEP.language_code_block = {"copy":"Copy code","copied":"Copied","fold":"Fold code block","folded":"Folded"}
    KEEP.language_copy_copyright = {"copy":"Copy copyright info","copied":"Copied","title":"Original post title","author":"Original post author","link":"Original post link"}
  </script>
<meta name="generator" content="Hexo 5.4.1"></head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <i class="pjax-progress-icon fas fa-circle-notch fa-spin"></i>
    
</div>


<main class="page-container border-box">

    <!-- home first screen  -->
    

    <!-- page content -->
    <div class="page-main-content border-box">
        <div class="page-main-content-top">
            
<header class="header-wrapper">

    <div class="border-box header-content">
        <div class="left border-box">
            
                <a class="logo-image border-box" href="/">
                    <img src="/images/atom.svg">
                </a>
            
            <a class="site-name border-box" href="/">
               Swift&#39;s Blog
            </a>
        </div>

        <div class="right border-box">
            <div class="pc">
                <ul class="menu-list">
                    <li class="menu-item">
                        <a class=""
                           href="/"
                        >HOME</a>
                    </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >ARCHIVES</a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/tags"
                            >TAGS</a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/categories"
                            >CATEGORIES</a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/links"
                            >LINKS</a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/about"
                            >ABOUT</a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas search fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            <li class="drawer-menu-item flex-center">
                <a class=""
                   href="/"
                >HOME</a>
            </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives"
                    >ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/tags"
                    >TAGS</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/categories"
                    >CATEGORIES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/links"
                    >LINKS</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/about"
                    >ABOUT</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle border-box">

            <div class="main-content border-box">
                

                    
<div class="fade-in-down-animation">
    <div class="post-page-container border-box">
        <div class="post-content-container border-box">
            

            <div class="post-content-bottom border-box">
                
                    <div class="post-title">
                        自定义CUDA算子融合实现模型推理加速
                    </div>
                

                
                    <div class="post-header border-box">
                        
                            <div class="avatar-box border-box">
                                <img src="/images/atom.svg">
                            </div>
                        
                        <div class="info-box">
                            <div class="author border-box">
                                <span class="name">Swift</span>
                                
                                    <span class="author-badge">Lv6</span>
                                
                            </div>
                            <div class="meta-info border-box">
                                

<div class="post-meta-info-container border-box post">
    <div class="post-meta-info border-box">
        

        
            <span class="meta-info-item post-create-date">
                <i class="icon fa-solid fa-file-pen"></i>&nbsp;
                <span class="datetime">2025-03-28 03:34:18</span>
            </span>

            <span class="meta-info-item post-update-date">
                <i class="icon fa-solid fa-rotate"></i>&nbsp;
                <span class="datetime" data-updated="Fri Mar 28 2025 03:34:18 GMT+0000">2025-03-28 03:34:18</span>
            </span>
        

        
            <span class="meta-info-item post-category border-box"><i class="icon fas fa-folder"></i>&nbsp;
                <ul class="post-category-ul">
                    
                            <li class="category-item"><a href="/categories/Machine-Learning/">Machine Learning</a></li>
                        
                    
                </ul>
            </span>
        

        
            <span class="post-tag meta-info-item border-box">
                <i class="icon fas fa-tags"></i>&nbsp;
                <ul class="post-tag-ul">
                    
                            <li class="tag-item"><span class="tag-separator"><i class="icon fas fa-hashtag"></i></span><a href="/tags/CUDA/">CUDA</a></li>
                        
                    
                </ul>
            </span>
        

        
        
        
        
            <span class="meta-info-item post-pv">
                <i class="icon fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
            </span>
        
    </div>

    
</div>

                            </div>
                        </div>
                    </div>
                

                <div class="post-content keep-markdown-body">
                    

                    <p>对模型进行推理加速的最常用方法就是算子融合，这里用个简单demo记录下：</p>
<span id="more"></span>
<p>总共有如下三个步骤：</p>
<h2 id="导出模型权重"><a href="#导出模型权重" class="headerlink" title="导出模型权重"></a>导出模型权重</h2><p>用pytorch定义一个多层DNN模型，然后导出其各层的网络参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># export_model.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义PyTorch模型结构</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DNNModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.layer1 = nn.Linear(<span class="number">100</span>, <span class="number">128</span>)</span><br><span class="line">        self.relu1 = nn.ReLU()</span><br><span class="line">        self.layer2 = nn.Linear(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line">        self.relu2 = nn.ReLU()</span><br><span class="line">        self.layer3 = nn.Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.relu1(self.layer1(x))</span><br><span class="line">        x = self.relu2(self.layer2(x))</span><br><span class="line">        <span class="keyword">return</span> self.layer3(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型并随机初始化</span></span><br><span class="line">model = DNNModel()</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导出权重为二进制文件</span></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    param.detach().cpu().numpy().tofile(<span class="string">f&quot;<span class="subst">&#123;name&#125;</span>.bin&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;权重导出完成！&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>运行 <code>python export_model.py</code> 。</p>
<h2 id="编写CUDA融合算子"><a href="#编写CUDA融合算子" class="headerlink" title="编写CUDA融合算子"></a>编写CUDA融合算子</h2><p>神经网络的每一层前向传播，都先从全局内存中读取tensor到寄存器内存，完成计算后再写回到全局内存，IO次数较多。利用算子融合，将多次计算融合成一次计算，减少IO读写，从而实现模型推理加速。</p>
<p>具体的代码包括如下三个步骤：</p>
<ol>
<li>加载pytorch导出的模型参数</li>
<li>将多次前向传播融合到一个函数中</li>
<li>将优化后的函数绑定到python模块中</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// fused_op.cu</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;torch/extension.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">fused_forward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">float</span>* input,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">float</span>* output,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">float</span>* W1, <span class="type">const</span> <span class="type">float</span>* b1,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">float</span>* W2, <span class="type">const</span> <span class="type">float</span>* b2,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">float</span>* W3, <span class="type">const</span> <span class="type">float</span>* b3,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int</span> batch_size, <span class="type">int</span> in_dim, <span class="type">int</span> hid1, <span class="type">int</span> hid2, <span class="type">int</span> out_dim</span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 每个线程处理一个样本的完整计算</span></span><br><span class="line">    <span class="type">int</span> sample_idx = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span> (sample_idx &gt;= batch_size) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 指向当前样本的输入和输出</span></span><br><span class="line">    <span class="type">const</span> <span class="type">float</span>* x = input + sample_idx * in_dim;</span><br><span class="line">    <span class="type">float</span>* out = output + sample_idx * out_dim;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 第一层：Linear + ReLU</span></span><br><span class="line">    <span class="type">float</span> hidden1[<span class="number">128</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; hid1; ++i) &#123;</span><br><span class="line">        <span class="type">float</span> sum = b1[i];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; in_dim; ++j) &#123;</span><br><span class="line">            sum += x[j] * W1[j * hid1 + i]; <span class="comment">// 转置访问权重</span></span><br><span class="line">        &#125;</span><br><span class="line">        hidden1[i] = <span class="built_in">fmaxf</span>(sum, <span class="number">0.0f</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 第二层：Linear + ReLU</span></span><br><span class="line">    <span class="type">float</span> hidden2[<span class="number">64</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; hid2; ++i) &#123;</span><br><span class="line">        <span class="type">float</span> sum = b2[i];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; hid1; ++j) &#123;</span><br><span class="line">            sum += hidden1[j] * W2[j * hid2 + i]; <span class="comment">// 转置访问权重</span></span><br><span class="line">        &#125;</span><br><span class="line">        hidden2[i] = <span class="built_in">fmaxf</span>(sum, <span class="number">0.0f</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 第三层：Linear</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; out_dim; ++i) &#123;</span><br><span class="line">        <span class="type">float</span> sum = b3[i];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; hid2; ++j) &#123;</span><br><span class="line">            sum += hidden2[j] * W3[j * out_dim + i]; <span class="comment">// 转置访问权重</span></span><br><span class="line">        &#125;</span><br><span class="line">        out[i] = sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">torch::Tensor <span class="title">fused_forward_cuda</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor input,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor W1, torch::Tensor b1,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor W2, torch::Tensor b2,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor W3, torch::Tensor b3</span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> batch_size = input.<span class="built_in">size</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="type">int</span> in_dim = W1.<span class="built_in">size</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="type">int</span> hid1 = W1.<span class="built_in">size</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="type">int</span> hid2 = W2.<span class="built_in">size</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="type">int</span> out_dim = W3.<span class="built_in">size</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    torch::Tensor output = torch::<span class="built_in">zeros</span>(&#123;batch_size, out_dim&#125;, input.<span class="built_in">options</span>());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 每个block处理多个样本，根据GPU配置调整</span></span><br><span class="line">    <span class="type">int</span> threads = <span class="number">256</span>;</span><br><span class="line">    <span class="type">int</span> blocks = (batch_size + threads - <span class="number">1</span>) / threads;</span><br><span class="line"></span><br><span class="line">    fused_forward&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(</span><br><span class="line">        input.<span class="built_in">data_ptr</span>&lt;<span class="type">float</span>&gt;(),</span><br><span class="line">        output.<span class="built_in">data_ptr</span>&lt;<span class="type">float</span>&gt;(),</span><br><span class="line">        W1.<span class="built_in">data_ptr</span>&lt;<span class="type">float</span>&gt;(),</span><br><span class="line">        b1.<span class="built_in">data_ptr</span>&lt;<span class="type">float</span>&gt;(),</span><br><span class="line">        W2.<span class="built_in">data_ptr</span>&lt;<span class="type">float</span>&gt;(),</span><br><span class="line">        b2.<span class="built_in">data_ptr</span>&lt;<span class="type">float</span>&gt;(),</span><br><span class="line">        W3.<span class="built_in">data_ptr</span>&lt;<span class="type">float</span>&gt;(),</span><br><span class="line">        b3.<span class="built_in">data_ptr</span>&lt;<span class="type">float</span>&gt;(),</span><br><span class="line">        batch_size, in_dim, hid1, hid2, out_dim</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">PYBIND11_MODULE</span>(TORCH_EXTENSION_NAME, m) &#123;</span><br><span class="line">    m.<span class="built_in">def</span>(<span class="string">&quot;fused_forward&quot;</span>, &amp;fused_forward_cuda, <span class="string">&quot;Fused forward pass (CUDA)&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述代码用到了<code>libtorch</code>库，不过我们不需要手动安装，只要本地有pytorch库就可以。在绑定python模块的时候，pytorch会自动将其转换。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># setup.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> setuptools <span class="keyword">import</span> setup</span><br><span class="line"><span class="keyword">from</span> torch.utils.cpp_extension <span class="keyword">import</span> CUDAExtension, BuildExtension</span><br><span class="line"></span><br><span class="line">setup(</span><br><span class="line">    name=<span class="string">&#x27;fused_op&#x27;</span>,</span><br><span class="line">    ext_modules=[</span><br><span class="line">        CUDAExtension(</span><br><span class="line">            name=<span class="string">&#x27;fused_op&#x27;</span>,</span><br><span class="line">            sources=[<span class="string">&#x27;fused_op.cu&#x27;</span>]  <span class="comment"># 根据GPU架构调整</span></span><br><span class="line">        )</span><br><span class="line">    ],</span><br><span class="line">    cmdclass=&#123;</span><br><span class="line">        <span class="string">&#x27;build_ext&#x27;</span>: BuildExtension</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>运行 <code>python setup.py install</code></p>
<h2 id="测试加速效果"><a href="#测试加速效果" class="headerlink" title="测试加速效果"></a>测试加速效果</h2><p>主要为了验证模型推理耗时和结果一致性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> fused_op  <span class="comment"># 导入CUDA模块</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载原始PyTorch模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DNNModel</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.layer1 = torch.nn.Linear(<span class="number">100</span>, <span class="number">128</span>)</span><br><span class="line">        self.relu1 = torch.nn.ReLU()</span><br><span class="line">        self.layer2 = torch.nn.Linear(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line">        self.relu2 = torch.nn.ReLU()</span><br><span class="line">        self.layer3 = torch.nn.Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.relu1(self.layer1(x))</span><br><span class="line">        x = self.relu2(self.layer2(x))</span><br><span class="line">        <span class="keyword">return</span> self.layer3(x)</span><br><span class="line"></span><br><span class="line">origin_model = DNNModel()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载原始模型的网络参数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_transposed_weights</span>(<span class="params">filename, original_shape</span>):</span><br><span class="line">    <span class="comment"># 从文件加载并重塑为转置后的形状</span></span><br><span class="line">    transposed_weights = np.fromfile(filename, dtype=np.float32)</span><br><span class="line">    transposed_shape = (original_shape[<span class="number">1</span>], original_shape[<span class="number">0</span>])  <span class="comment"># 交换维度</span></span><br><span class="line">    <span class="keyword">return</span> torch.from_numpy(</span><br><span class="line">        transposed_weights.reshape(transposed_shape).T  <span class="comment"># 转置回原始形状</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">origin_model.layer1.weight.data = load_transposed_weights(<span class="string">&quot;layer1.weight.bin&quot;</span>, (<span class="number">128</span>, <span class="number">100</span>))</span><br><span class="line">origin_model.layer2.weight.data = load_transposed_weights(<span class="string">&quot;layer2.weight.bin&quot;</span>, (<span class="number">64</span>, <span class="number">128</span>))</span><br><span class="line">origin_model.layer3.weight.data = load_transposed_weights(<span class="string">&quot;layer3.weight.bin&quot;</span>, (<span class="number">10</span>, <span class="number">64</span>))</span><br><span class="line">origin_model.layer1.bias.data = torch.from_numpy(np.fromfile(<span class="string">&quot;layer1.bias.bin&quot;</span>, dtype=np.float32))</span><br><span class="line">origin_model.layer2.bias.data = torch.from_numpy(np.fromfile(<span class="string">&quot;layer2.bias.bin&quot;</span>, dtype=np.float32))</span><br><span class="line">origin_model.layer3.bias.data = torch.from_numpy(np.fromfile(<span class="string">&quot;layer3.bias.bin&quot;</span>, dtype=np.float32))</span><br><span class="line"></span><br><span class="line">origin_model = origin_model.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试函数（返回时间和结果）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">measure_time</span>(<span class="params">func, input_data, repeats=<span class="number">30</span></span>):</span><br><span class="line">    timings = []</span><br><span class="line">    outputs = []</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(repeats):</span><br><span class="line">            start = time.time()</span><br><span class="line">            output = func(input_data)</span><br><span class="line">            end = time.time()</span><br><span class="line">            timings.append(end - start)</span><br><span class="line">            outputs.append(output)</span><br><span class="line">    <span class="keyword">return</span> np.mean(timings), outputs[<span class="number">0</span>]  <span class="comment"># 返回平均时间和单次结果</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备输入数据并固定随机种子</span></span><br><span class="line"><span class="comment"># np.random.seed(42)</span></span><br><span class="line"><span class="comment"># torch.manual_seed(42)</span></span><br><span class="line">input_data = torch.randn(<span class="number">32</span>, <span class="number">100</span>, dtype=torch.float32).cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载优化后的模型权重，并将其作为参数传入</span></span><br><span class="line">layer1_weight = origin_model.layer1.weight</span><br><span class="line">layer2_weight = origin_model.layer2.weight</span><br><span class="line">layer3_weight = origin_model.layer3.weight</span><br><span class="line">layer1_bias = origin_model.layer1.bias</span><br><span class="line">layer2_bias = origin_model.layer2.bias</span><br><span class="line">layer3_bias = origin_model.layer3.bias</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试原始模型</span></span><br><span class="line">origin_time, origin_output = measure_time(<span class="keyword">lambda</span> x: origin_model(x), input_data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;原始PyTorch推理时间: <span class="subst">&#123;origin_time * <span class="number">1000</span>:<span class="number">.2</span>f&#125;</span> ms&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试CUDA融合模块</span></span><br><span class="line">optimised_time, optimised_output = measure_time(</span><br><span class="line">    <span class="keyword">lambda</span> x: fused_op.fused_forward(x, layer1_weight, layer1_bias, layer2_weight, layer2_bias, layer3_weight, layer3_bias), input_data</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;CUDA融合推理时间: <span class="subst">&#123;optimised_time * <span class="number">1000</span>:<span class="number">.2</span>f&#125;</span> ms&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果对比</span></span><br><span class="line">native_result = origin_output.cpu().numpy()</span><br><span class="line">cuda_result = optimised_output.cpu().numpy()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">abs_diff = np.<span class="built_in">abs</span>(native_result - cuda_result)</span><br><span class="line">max_abs_diff = np.<span class="built_in">max</span>(abs_diff)</span><br><span class="line">rel_diff = np.mean(abs_diff / (np.<span class="built_in">abs</span>(native_result) + <span class="number">1e-8</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;最大绝对误差: <span class="subst">&#123;max_abs_diff:<span class="number">.6</span>e&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;平均相对误差: <span class="subst">&#123;rel_diff:<span class="number">.6</span>e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> max_abs_diff &lt; <span class="number">1e-5</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;✅ 结果一致，优化成功！&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;❌ 结果不一致，可能存在错误！&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>运行 <code>python test.py</code>：</p>
<p><img   src="https://github.com/TransformersWsz/picx-images-hosting/raw/master/image.3goknytxty.webp"  alt="result"></p>
<hr>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://github.com/TransformersWsz/cuda_examples/blob/main/op_fuse/README.md" >op_fuse<i class="fas fa-external-link-alt"></i></a></li>
</ul>

                </div>

                

                <div class="post-bottom-tags-and-share border-box">
                    <div>
                        
                            <ul class="post-tags-box border-box">
                                
                                    <li class="tag-item border-box">
                                        <i class="icon fas fa-hashtag"></i>&nbsp;<a href="/tags/CUDA/">CUDA</a>
                                    </li>
                                
                            </ul>
                        
                    </div>
                    <div>
                        
                            <div class="post-share-container border-box">
    <ul class="share-list-wrap border-box">
        <li class="qq share-item border-box flex-center tooltip"
            data-tooltip-content="Share to QQ"
        >
            <i class="fa-brands fa-qq"></i>
        </li>
        <li class="wechat share-item border-box flex-center tooltip tooltip-img"
            data-tooltip-content="Share to WeChat"
            data-tooltip-img-tip="Scan by WeChat"
            data-tooltip-img-style="background-color: #fff; top: -10px; padding: 0.6rem 0.6rem 0.1rem 0.6rem;"
        >
            <i class="fa-brands fa-weixin"></i>
        </li>
        <li class="weibo share-item border-box flex-center tooltip"
            data-tooltip-content="Share to WeiBo"
        >
            <i class="fa-brands fa-weibo"></i>
        </li>
    </ul>
</div>

                        
                    </div>
                </div>

                
                    <div class="reward-author-container border-box flex-center">
    <div class="reward-btn keep-button border-box flex-center tooltip tooltip-img"
            data-tooltip-content="请作者喝杯奶茶🧋"
            data-tooltip-img-url="https://github.com/TransformersWsz/picx-images-hosting/raw/master/code6.8s3kp5tiv9.webp"
            data-tooltip-img-trigger="click"
            data-tooltip-img-style="top: -8px;"
    >
        <i class="fa-solid fa-hand-holding-heart"></i>
    </div>
</div>

                

                
                    <div class="post-nav border-box">
                        
                            <div class="prev-post">
                                <a class="prev"
                                   rel="prev"
                                   href="/2025/03/29/%E6%9C%89%E9%99%90%E9%A2%84%E7%AE%97%E5%88%86%E9%85%8D%E4%B8%8B%E7%9A%8401%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"
                                   title="有限预算分配下的01背包问题"
                                >
                                    <span class="left arrow-icon flex-center">
                                        <i class="fas fa-chevron-left"></i>
                                    </span>
                                    <span class="title flex-center">
                                        <span class="post-nav-title-item text-ellipsis">有限预算分配下的01背包问题</span>
                                        <span class="post-nav-item">Prev posts</span>
                                    </span>
                                </a>
                            </div>
                        
                        
                            <div class="next-post">
                                <a class="next"
                                   rel="next"
                                   href="/2025/03/22/%E7%94%A8tensorboard%E6%94%AF%E6%8C%81pytorch%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/"
                                   title="用tensorboard支持pytorch训练可视化"
                                >
                                    <span class="title flex-center">
                                        <span class="post-nav-title-item text-ellipsis">用tensorboard支持pytorch训练可视化</span>
                                        <span class="post-nav-item">Next posts</span>
                                    </span>
                                    <span class="right arrow-icon flex-center">
                                        <i class="fas fa-chevron-right"></i>
                                    </span>
                                </a>
                            </div>
                        
                    </div>
                

                
                    






                
            </div>
        </div>

        
            <div class="pc-post-toc left-toc">
                <div class="post-toc-wrap border-box">
    <div class="post-toc border-box">
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%BC%E5%87%BA%E6%A8%A1%E5%9E%8B%E6%9D%83%E9%87%8D"><span class="nav-number">1.</span> <span class="nav-text">导出模型权重</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%96%E5%86%99CUDA%E8%9E%8D%E5%90%88%E7%AE%97%E5%AD%90"><span class="nav-number">2.</span> <span class="nav-text">编写CUDA融合算子</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95%E5%8A%A0%E9%80%9F%E6%95%88%E6%9E%9C"><span class="nav-number">3.</span> <span class="nav-text">测试加速效果</span></a></li></ol>
    </div>
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom border-box">
            
<footer class="footer border-box">
    <div class="border-box website-info-box default">
        
            <div class="copyright-info info-item default">
                &copy;&nbsp;<span>2017</span>&nbsp;-&nbsp;2025
                
                    &nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;&nbsp;<a href="/">Swift</a>
                
            </div>

            <div class="theme-info info-item default">
                Powered by&nbsp;<a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;&&nbsp;Theme&nbsp;<a class="keep-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep</a>
            </div>

            

            
                
                <div class="deploy-info info-item default">
                    
                        This site is deployed on <span class="tooltip" data-tooltip-content="GitHub Pages"><img src="/images/deploy-provider/github.png"></span>
                    
                </div>
            
        

        <div class="count-item info-item default">
            

            
                <span class="count-box border-box uv">
                    <span class="item-type border-box">Unique Visitor</span>
                    <span class="item-value border-box uv" id="busuanzi_value_site_uv"></span>
                </span>
            

            
                <span class="count-box border-box pv">
                    <span class="item-type border-box">Page View</span>
                    <span class="item-value border-box pv" id="busuanzi_value_site_pv"></span>
                </span>
            
        </div>
    </div>
</footer>

        </div>
    </div>

    <!-- post tools -->
    
        <div class="post-tools left-toc">
            <div class="post-tools-container border-box">
    <ul class="tools-list border-box">
        <!-- PC TOC show toggle -->
        
            <li class="tools-item flex-center toggle-show-toc">
                <i class="fas fa-list"></i>
            </li>
        

        <!-- PC go comment -->
        
    </ul>
</div>

        </div>
    

    <!-- side tools -->
    <div class="side-tools">
        <div class="side-tools-container border-box ">
    <ul class="side-tools-list side-tools-show-handle border-box">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-toggle-theme-mode flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list border-box">
        
            <li class="tools-item toggle-show-toc-tablet flex-center">
                <i class="fas fa-list"></i>
            </li>
        

        

        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>

        <li class="tools-item tool-scroll-to-top flex-center show-arrow">
            <i class="arrow fas fa-arrow-up"></i>
            <span class="percent"></span>
        </li>
    </ul>
</div>

    </div>

    <!-- image mask -->
    <div class="zoom-in-image-mask">
    <img class="zoom-in-image">
</div>


    <!-- local search -->
    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="close-popup-btn">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

    <!-- tablet toc -->
    
        <div class="tablet-post-toc-mask">
            <div class="tablet-post-toc">
                <div class="post-toc-wrap border-box">
    <div class="post-toc border-box">
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%BC%E5%87%BA%E6%A8%A1%E5%9E%8B%E6%9D%83%E9%87%8D"><span class="nav-number">1.</span> <span class="nav-text">导出模型权重</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%96%E5%86%99CUDA%E8%9E%8D%E5%90%88%E7%AE%97%E5%AD%90"><span class="nav-number">2.</span> <span class="nav-text">编写CUDA融合算子</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95%E5%8A%A0%E9%80%9F%E6%95%88%E6%9E%9C"><span class="nav-number">3.</span> <span class="nav-text">测试加速效果</span></a></li></ol>
    </div>
</div>

            </div>
        </div>
    
</main>



<!-- common -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.0.7/js/utils.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.0.7/js/header-shrink.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.0.7/js/back2top.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.0.7/js/toggle-theme.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.0.7/js/code-block.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.0.7/js/main.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.0.7/js/libs/anime.min.js"></script>

<!-- local-search -->

    <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.0.7/js/local-search.min.js"></script>


<!-- lazyload -->


<div class="pjax">
    
        <!-- post-helper -->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.0.7/js/post/post-helper.min.js"></script>

        <!-- toc -->
        
            <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.0.7/js/post/toc.min.js"></script>
        

        <!-- copyright-info -->
        

        <!-- share -->
        
            <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.0.7/js/post/share.min.js"></script>
        
    

    <!-- category-page -->
    

    <!-- links-page -->
    

    <!-- photos-page -->
    
</div>

<!-- mermaid -->

    
<script src="//cdn.jsdelivr.net/npm/mermaid@10.5.0/dist/mermaid.min.js"></script>

    <script data-pjax>
      if (window.mermaid) {
        mermaid.init()
      }
    </script>






<!-- pjax -->

    <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.0.7/js/libs/pjax.min.js"></script>
<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart()
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd()
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'))
            KEEP.initExecute()
        });
    });
</script>




    
        
    

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body>
</html>
